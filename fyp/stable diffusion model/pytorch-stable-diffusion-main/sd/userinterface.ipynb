{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:01<00:00,  6.12s/it]\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "from flask.helpers import send_file\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import loader\n",
    "import modelpipeline\n",
    "from transformers import CLIPTokenizer\n",
    "import torch\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "ALLOW_CUDA = True\n",
    "ALLOW_MPS = False\n",
    "\n",
    "if torch.cuda.is_available() and ALLOW_CUDA:\n",
    "    DEVICE = \"cuda\"\n",
    "elif (torch.backends.mps.is_built() or torch.backends.mps.is_available()) and ALLOW_MPS:\n",
    "    DEVICE = \"mps\"\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "tokenizer = CLIPTokenizer(\"../data/vocab.json\", merges_file=\"../data/merges.txt\")\n",
    "model_file = \"../data/v1-5-pruned-emaonly.ckpt\"\n",
    "models = loader.preload_models_from_standard_weights(model_file, DEVICE)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route(\"/generate\", methods=[\"POST\"])\n",
    "def generate():\n",
    "    prompt = request.form.get(\"prompt\")\n",
    "    uncond_prompt = request.form.get(\"uncond_prompt\")\n",
    "    strength = float(request.form.get(\"strength\"))\n",
    "\n",
    "    image = request.files[\"image\"]\n",
    "    input_image = Image.open(image)\n",
    "\n",
    "    do_cfg = True  # Example value, modify as needed\n",
    "    cfg_scale = 8  # Example value, modify as needed\n",
    "    sampler = \"ddpm\"  # Example value, modify as needed\n",
    "    num_inference_steps = 50  # Example value, modify as needed\n",
    "    seed = 42  # Example value, modify as needed\n",
    "\n",
    "    output_image = modelpipeline.generate(\n",
    "        prompt=prompt,\n",
    "        uncond_prompt=uncond_prompt,\n",
    "        input_image=input_image,\n",
    "        strength=strength,\n",
    "        do_cfg=do_cfg,\n",
    "        cfg_scale=cfg_scale,\n",
    "        sampler_name=sampler,\n",
    "        n_inference_steps=num_inference_steps,\n",
    "        seed=seed,\n",
    "        models=models,\n",
    "        device=DEVICE,\n",
    "        idle_device=\"cpu\",\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    output_buffer = BytesIO()\n",
    "    output_image.save(output_buffer, format=\"PNG\")\n",
    "    output_buffer.seek(0)\n",
    "\n",
    "    return send_file(output_buffer, mimetype=\"image/png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stable-diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
